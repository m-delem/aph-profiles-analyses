---
title: Data Analysis Report
subtitle: "Uncovering spatial and verbal cognitive profiles in aphantasia 
  through unsupervised clustering"
# setting for proper numbering of sections
crossref: 
  chapters: true
  custom:
    - kind: float
      key: suppfig
      reference-prefix: Figure S
      space-before-numbering: false
    - kind: float
      key: supptbl
      reference-prefix: Table S
      space-before-numbering: false
supptbl-cap-location: top
echo: false # do not show the code unless explicitly asked
params:
  save_figures: true
format: html
---

This document contains the entire data analysis process and an in-depth 
presentation of the results related to the article in the sub-title. 
These analyses should be fully reproducible. See the tab below for the details 
on how to do so.

:::{.callout-tip collapse="true"}
# How to reproduce the analyses

You may have found this document either in the 
[GitHub repository](https://github.com/m-delem/aph-profiles-analyses/tree/main) 
of this analysis project, or archived in the 
[OSF repository](https://osf.io/7vsx6/) of this study, which additionally 
contains all the experimental material to replicate the study.

Either way, what you want to do is to have the complete project as a folder on 
your computer.

- If you use Git, clone the repo from GitHub.
- If you've never used Git, first, I'd recommend 
  [you start using it](https://happygitwithr.com/), else you have two options:
  
    - Go on the 
      [repo's page](https://github.com/m-delem/aph-profiles-analyses/tree/main), 
      click the green "Code" button and "Download ZIP". Extract the ZIP anywhere 
      you want on your computer.
    - Go on the [OSF files page](https://osf.io/7vsx6/files/osfstorage) of the 
      study, download the "analysis-project.zip" file and extract the ZIP 
      anywhere you want on your computer.

This project requires installing [Quarto](https://quarto.org/) on your computer, 
and I'd recommend using it with 
[RStudio](https://posit.co/download/rstudio-desktop/).

- Open the `open-this-file-first.Rproj` file. This should open RStudio and set 
  the directory you created as the working directory. This directory is an "R 
  Project" (in this case, a "Quarto project"). 
  
- This project has its own "environment" thanks to the `renv` package, 
  which means that the project is independent from your computer in terms of 
  packages. What happens in this project, stays in this project. The packages 
  installed on your computer will not be modified, but conversely they are not
  automatically available in the project either. I added code in the `.Rprofile`
  file that runs on start-up and restores the necessary packages in the 
  project's directory, so you won't have to worry about this.
  
- Open the `analysis-report.qmd` file (you can see your files in RStudio's 
  right panel). This is a Quarto file, which allows mixing plain text with 
  pieces of code called "chunks" (and many, many other cool features). The 
  present report is generated from this file.
  
- Press `Ctrl + Alt + R` (if you are on Windows), or click the "Run" drop-down 
  on the top right of the script window, and "Run All". This will start running
  all the chunks in the file.

Then all the chunks below will run in sequence. Bayesian models should be saved 
in the repo and will be loaded quickly to avoid recomputing. Plots will be 
produced and displayed. If you want to re-run the Bayesian models, simply rename 
the files in `data/r-data-structures` and run everything again to get new 
models. Note that Bayesian modelling is probabilistic, so there will be slight 
variations between each run, but *stable models are stable*.

Done! You have everything you need to check things out, to test new things 
and play around if you want. There are probably more things to find in this 
data, but I've done my best. Thank you for your interest in this research, and 
most of all, for digging this far. This whole exploration has required a 
tremendous amount of work and dedication, but I've often doubted that anyone 
would ***ever*** read this document (let alone this drop-down tab with technical 
stuff), so I'm really, really grateful.
:::

The tab below displays all the (heavily commented) code necessary to replicate 
these analyses. The raw R scripts with the functions can be found in the `R/` 
folder.

:::: {.callout-note collapse="true"}
# Packages and pipeline

```{r}
#| label: setup
#| echo: true
#| code-fold: false

pacman::p_load(mclust, patchwork) # Arranging multiple ggplots

# Source all our custom functions
here::here("R") |> 
  fs::dir_ls(type = "file", recurse = TRUE) |> 
  purrr::walk(source)

# Resolve package conflicts
conflicted::conflicts_prefer(
  dplyr::filter(), 
  dplyr::select(),
  scales::rescale(), 
  purrr::map(),
  .quiet = TRUE
  )
```

Most of the steps of the data analysis were performed using functions defined in 
external R scripts in the `R/` folder (loaded in the chunk above). 
The interested reader can find their code in the tab below. 

:::{.callout-note collapse="true"}
## Custom functions

First, the `import_jatos_data` is a long function that extracts the data from the
raw JATOS files, tidies it, computes various scores, exports data for manual scoring
or loads the manually scored data, exports the data to Excel, CSV and RDS formats,
and returns a list with the data and metadata. This way, the data used is always
recreated from the raw data, enhancing reproducibility.

```{r}
#| label: add-import
#| add-from: R/01_import/import_jatos_data.R
#| code-summary: Data import function
#| echo: true

#
```

Four functions were created to manipulate the data in various ways.

```{r}
#| label: add-scale-vars
#| add-from: R/02_wrangle/scale_vars.R
#| code-summary: Scale variables from their original range to 0-1
#| echo: true

#
```

```{r}
#| label: add-scale-reduce-vars
#| add-from: R/02_wrangle/scale_reduce_vars.R
#| code-summary: "Scale variables and compute reduced variables (based on correlations)"
#| echo: true

#
```

```{r}
#| label: add-merge
#| add-from: R/02_wrangle/merge_clusters.R
#| code-summary: Add the clusters computed to the main dataframe
#| echo: true

#
```

```{r}
#| label: add-longer
#| add-from: R/02_wrangle/get_longer.R
#| code-summary: Pivot the table to a long format and use pretty names
#| echo: true

#
```

Three functions were dedicated to modelling tasks.

```{r}
#| label: add-correlate
#| add-from: R/03_model/correlate_vars.R
#| code-summary: Compute correlations or partial correlations on the original variables
#| echo: true

#
```

```{r}
#| label: add-model-groups
#| add-from: R/03_model/model_groups.R
#| code-summary: "Model all the variables with the groups, clusters or subclusters (+ age) as predictors"
#| echo: true

#
```

```{r}
#| label: add-model-lives
#| add-from: R/03_model/model_lives.R
#| code-summary: Assess association of education, field of study and occupation with Group, etc.
#| echo: true

#
```

Finally, four functions were created to plot the data, a helper function was used
to save figures in appropriate formats conveniently, and a function helped 
generating $\LaTeX$ tables automatically for the manuscript.

```{r}
#| label: add-violins
#| add-from: R/04_plot/plot_violins.R
#| code-summary: Plot group scores as violin-dot figures
#| echo: true

#
```

```{r}
#| label: add-radars
#| add-from: R/04_plot/plot_radars.R
#| code-summary: Plot group, cluster or subcluster scores as radars
#| echo: true

#
```

```{r}
#| label: add-correlation-plots
#| add-from: R/04_plot/plot_correlations.R
#| code-summary: Plot correlation matrices and graphs
#| echo: true

#
```

```{r}
#| label: add-bic
#| add-from: R/04_plot/plot_clusters_bic.R
#| code-summary: Plot BIC evaluation of GMMs for clustering
#| echo: true

#
```

```{r}
#| label: add-save
#| add-from: R/04_plot/save_plot.R
#| code-summary: Save plots in appropriate formats
#| echo: true

#
```

```{r}
#| label: add-latex
#| add-from: R/04_plot/get_latex_table.R
#| code-summary: "Print $\\LaTeX$ tables for the manuscript"
#| echo: true

#
```
:::

The pipeline code below then runs all of these functions sequentially, 
sometimes saving heavy computations along the way. It saves the figures if this
notebook was parametrised to do so with `params: save_figures: true`.
This pipeline is designed to run smoothly for anyone using the `renv` 
R environment from the project that has the raw JATOS data stored in the 
`data/raw-data/` directory and the manually scored Similarities and Reading 
comprehension tests in the `data/data-processed/data_scored_manually.xlsx` file.

```{r}
#| label: pipeline
#| code-summary: Data analysis pipeline
#| echo: true
#| warning: false

# Load the data directly from the raw files
df <- import_jatos_data()$data_final

# Compute simple and partial correlations
corrs_simple  <- correlate_vars(df, partial = FALSE, correction = "bonferroni")
corrs_partial <- correlate_vars(df, partial = TRUE,  correction = "bonferroni")

# Variables selected for clustering after the analysis of partial correlations
selected_vars <- c(
  "visual_imagery", "sensory_imagery", 
  "spatial_imagery", "verbal_strategies",
  "fluid_intelligence", "verbal_reasoning", 
  "span_spatial"
)

# Determine the best model (GMM) and number of clusters for clustering with BIC
bic <- df |> 
  scale_reduce_vars() |> 
  select(any_of(selected_vars)) |> 
  mclustBIC()

# Compute the clustering on the selected variables with the selected model
clustering <- 
  df |> 
  scale_reduce_vars() |> 
  select(any_of(selected_vars)) |>
  Mclust(verbose = FALSE)

# Add the clusters and the reduced variables to the main dataset
df2 <- merge_clusters(df_raw = df, df_red = scale_reduce_vars(df), clustering)

# Create a long format of this final dataset for modelling and plotting
df_long <- df2 |> scale_vars() |> get_longer()

# Model all the variables with the groups, clusters and subclusters and save
# them, or simply load them if they exist in the files 
models_path <- here::here("data/r-data-structures/models.rds")

if (!fs::file_exists(models_path)) {
  group_models      <- df2 |> get_longer() |> model_groups(groups = Group)
  cluster_models    <- df_long |> model_groups(groups = Cluster)
  subcluster_models <- df_long |> model_groups(groups = Subcluster)
  
  models <- list(
    group_models      = group_models,
    cluster_models    = cluster_models,
    subcluster_models = subcluster_models
  )
  
  saveRDS(models, models_path)
  
  } else models <- readRDS(models_path)

# Model the education, field of study and occupation with groups, etc.
lives <- list(
  group      = model_lives(df2, group),
  cluster    = model_lives(df2, cluster),
  subcluster = model_lives(df2, subcluster)
)

# Produce the plots for all these outputs --------------------------------------

# The group comparisons, as violins...
p_groups_violins <- plot_violins(df_long, var_selection = "original")
# ...and as radars
p_groups_radars  <- plot_radars(df_long, Group,  var_selection = "original")

# Correlation matrices and graphs
p_partial <- plot_correlations(corrs_partial)
p_simple  <- plot_correlations(corrs_simple)

# BIC values for all models and number of clusters tested
p_bic <- plot_clusters_bic(clustering)

# Radars of the cluster and subcluster scores
p_clusters <- 
  plot_radars(df_long, Cluster,    r_off = 6) +
  plot_radars(df_long, Subcluster, l_off = 6)

# Save the figures if this notebook is parametrised to do so
if (params$save_figures) {
  save_plot(
    p_groups_violins, 
    "figures/groups-violins.pdf", 
    ncol = 2, height = 88)
  save_plot(
    p_groups_radars, 
    "figures/groups-radars.pdf", 
    ncol = 1, height = 88)
  
  save_plot(
    p_partial, 
    "figures/correlations-partial.pdf", 
    ncol = 2, height = 120)
  save_plot(
    p_simple, 
    "figures/correlations-simple.pdf", 
    ncol = 2,  height = 120)
  
  save_plot(
    p_bic, 
    "figures/clusters-bic.pdf", 
    ncol = 1, height = 88)
  save_plot(
    p_clusters, 
    "figures/clusters-radars.pdf", 
    ncol = 2, height = 90)
}
```
::::

# VVIQ group analysis

We first analysed the data in light of the VVIQ groups, examining differences 
between individuals with aphantasia and controls. 

## Main variables

In order to model our variables with the VVIQ groups, 
we adjusted generalized linear models also controlling the effect of age on all 
variables to isolate the group effect:

$$Variable = \alpha  + \beta_{1} \cdot Group \times \beta_{2} \cdot Age + \epsilon$$

### Visualisations

::::{.panel-tabset .column-page-inset}
#### Violin plots

::: {#suppfig-g-violins}
```{r}
#| label: g-violins
#| fig-width: 10
#| fig-height: 5

plot_violins(
  df_long, var_selection = "original",
  txt_big  = 12,
  txt_mid  = 10,
  txt_smol = 8,
  dot_big  = 0.5,
  dot_smol = 0.25,
  lw_big   = 0.5,
  lw_smol  = 0.5
  )
```

Scores of the two VVIQ groups on all the questionnaires and tasks. The scores have been rescaled between 0 and 1 to be represented on the same scale. The coloured shapes represent the distribution of the scores in each group. The coloured dots represent the mean of each group, while the bars represent the standard deviations. The stars represent weight of evidence thresholds in favour of an effect of the Group: \* = '*Substantial evidence*', \** = 'Strong evidence', \*** = 'Decisive evidence'.
:::

#### Radar plot

::: {#suppfig-g-radars}
```{r}
#| label: g-radars
#| fig-width: 6
#| fig-height: 6

plot_radars(
  df_long, Group,  var_selection = "original",
  txt_big  = 12,
  txt_mid  = 10,
  txt_smol = 8,
  dot_size = 1.5,
  lw       = 0.5
  )
```

Scores of the two VVIQ groups on all the questionnaires and tasks. The scores have been rescaled between 0 and 1 to be represented on the same scale. The coloured dots represent the mean of each group, while the bars represent the standard errors
:::
::::

### Full results

:::{#supptbl-g-results .column-page-inset}
```{r}
#| label: g-results

models$group_models |>
  select(!Comparison) |> 
  filter(!(Variable %in% c(
    "Visual imagery",
    "Auditory imagery",
    "Sensory imagery",
    "Spatial imagery",
    "Verbal strategies",
    "Raven +\nDigit Span",
    "Non-verbal\nreasoning",
    "Verbal reasoning",
    "Spatial span std."
  ))) |> 
  knitr::kable()
```

Means and standard deviations of the scores of each VVIQ group for every variable. The weight of evidence for a main effect of Group, Age and Group $\times$ Age, the score differences, their 95% Credible Interval and weight of evidence in favour of a difference between the groups are reported for each variable.
:::

## Demographic variables

:::{#supptbl-g-lives layout-ncol=2 .column-page-inset}
```{r}
#| label: tbl-g-lives-bf
#| tbl-cap: Weight of evidence in favour of an association between the variables and the VVIQ groups.

lives$group |> 
  select(1, 4) |> 
  rename(`$log(BF_{10})$` = log_bf10) |> 
  knitr::kable()
```


```{r}
#| label: tbl-g-lives-edu
#| tbl-cap: Distribution of education levels.

show_lives(lives$group, "Education")
```


```{r}
#| label: tbl-g-lives-field
#| tbl-cap: Distribution of the fields of education.

show_lives(lives$group, "Field")
```


```{r}
#| label: tbl-g-lives-occupation
#| tbl-cap: Distribution of occupational fields.

show_lives(lives$group, "Occupation")
```


Complete summary of the education, fields of the study and occupation data from the sample, classified with the VVIQ.
:::

# Cluster analysis

## Correlations

We used partial correlations to identify the strongest links between variables 
for variable reduction while reducing the bias from potential spurious correlations.
Standard Pearson correlations are also provided below as a reference for comparison.
All *p*-values are Bonferroni-corrected.

::::{.panel-tabset .column-page-inset}
### Partial correlations

:::{#suppfig-p-corrs}
```{r}
#| label: p-corrs
#| fig-width: 14
#| fig-height: 9

plot_correlations(
  corrs_partial,
  axis_text   = 10,
  matrix_text = 8,
  node_size   = 24,
  node_text_size  = 8,
  label_text_size = 4
  )
```

Partial correlations between all 18 original variables.
:::

### Simple correlations

:::{#suppfig-s-corrs}
```{r}
#| label: s-corrs
#| fig-width: 14
#| fig-height: 9

plot_correlations(
  corrs_simple,
  axis_text   = 10,
  matrix_text = 8,
  node_size   = 24,
  node_text_size  = 8,
  label_text_size = 4
  )
```

Simple correlations between all 18 original variables.
:::
::::

These analyses allowed us to remove redundant variables and select or create 
7 essential variables for clustering: *Visual imagery* (VVIQ + OSIVQ-Object + Psi-Q),
*Spatial imagery* (OSIVQ-Spatial + SRI), *Verbal strategies* (OSIVQ-Verbal),
*Sensory imagery* (Psi-Q smell + taste + touch + sensations + feelings),
*Raven + Digit span*, *Spatial span*, and *Verbal reasoning* (Similarities test).
*Auditory imagery* (Psi-Q Audition), *WCST* and *Reading comprehension* were 
not used for clustering and kept as external variables to test the cluster model.

## Number of clusters

We used Gaussian Mixture Models implemented in the package `mclust`. To determine
the ideal number of clusters, we used the Bayesian Information Criterion (BIC)
to test the fit of every model for every (reasonable) number of clusters.
This analysis showed that a 3-cluster model was the most appropriate.

:::{#suppfig-bic}
```{r}
#| label: p-bic
#| fig-width: 8
#| fig-height: 6

plot_clusters_bic(
  clustering,
    txt_big  = 10,
    txt_mid  = 9,
    txt_smol = 8,
    size = 0.5
  )
```

Comparison of the goodness of fit of different mixture models used for clustering as a function of model type and number of components. A high BIC indicates a good model fit. The three-letter acronyms describe the components of the mixture models. The first letter describes the volume of the components, the second their shape and the last their orientation. E = equal, V = variable. Acronyms ending with ‘II’ indicate mixtures of spherical components, those ending with ‘I’ indicate mixtures of diagonal components and those without 'I' indicate mixtures of ellipsoidal components.
:::

## Clustering results

```{css, echo=FALSE}
.center-table table {
  width: 50%;
  margin-left: auto;
  margin-right: auto;
}
```

:::{#supptbl-repartition .center-table}
```{r}
#| label: c-repartition

df2 |> 
  group_by(cluster, group) |> 
  count() |> 
  rename_with(str_to_title, everything()) |> 
  knitr::kable()
```

Distribution of the two initial groups in the three clusters obtained.
:::

The three clusters, when crossed with the VVIQ classification, reveal four
"sub-clusters" by dividing the mixed cluster between controls and individuals 
with aphantasia. We display the analyses for the cluster and sub-cluster 
classifications below.

### Main variables

::: {#suppfig-cluster-radars .column-page-inset}
```{r}
#| label: cluster-radar-plots
#| fig-width: 10
#| fig-height: 5

plot_radars(
  df_long, Cluster,  
  txt_big  = 9,
  txt_mid  = 8,
  txt_smol = 7,
  dot_size = 1.5,
  lw       = 0.5,
  y_off    = 57, # to center the y axis text
  r_off = 6) +
  plot_radars(
    df_long, Subcluster, 
    txt_big  = 9,
    txt_mid  = 8,
    txt_smol = 7,
    dot_size = 1.5,
    lw       = 0.5,
    y_off    = 57, # to center the y axis text
    l_off = 6)
```

Mean scores (points) and standard errors (error bars) of the three clusters on 
the seven variables used for clustering and the three test variables.
:::

### All variables

::::{.panel-tabset .column-page-inset}
#### Cluster models

:::{.panel-tabset}
##### Main effects

```{r}
models$cluster_models |> 
  select(1:7) |> 
  distinct() |> 
  knitr::kable()
```

##### Pairwise comparisons

```{r}
models$cluster_models |> 
  select(1, 8:11) |> 
  knitr::kable()
```
:::

#### Subcluster models

:::{.panel-tabset}
##### Main effects

```{r}
models$subcluster_models |> 
  select(1:8) |> 
  distinct() |> 
  knitr::kable()
```

##### Pairwise comparisons

```{r}
models$subcluster_models |> 
  select(1, 9:12) |> 
  knitr::kable()
```
:::
::::

### Demographic variables

#### Clusters

:::{#supptbl-c-lives layout-ncol=2 .column-page-inset}
```{r}
#| label: tbl-c-lives-bf
#| tbl-cap: Weight of evidence in favour of an association between the variables and the clusters.

lives$cluster |> 
  select(1, 4) |> 
  rename(`$log(BF_{10})$` = log_bf10) |> 
  knitr::kable()
```


```{r}
#| label: tbl-c-lives-edu
#| tbl-cap: Distribution of education levels.

show_lives(lives$cluster, "Education")
```


```{r}
#| label: tbl-c-lives-field
#| tbl-cap: Distribution of the fields of education.

show_lives(lives$cluster, "Field")
```


```{r}
#| label: tbl-c-lives-occupation
#| tbl-cap: Distribution of occupational fields.

show_lives(lives$cluster, "Occupation")
```


Complete summary of the education, fields of the study and occupation data from the sample, classified with the cluster model.
:::

#### Subclusters

:::{#supptbl-s-lives layout-ncol=2 .column-page-inset}
```{r}
#| label: tbl-s-lives-bf
#| tbl-cap: Weight of evidence in favour of an association between the variables and the clusters.

lives$subcluster |> 
  select(1, 4) |> 
  rename(`$log(BF_{10})$` = log_bf10) |> 
  knitr::kable()
```


```{r}
#| label: tbl-s-lives-edu
#| tbl-cap: Distribution of education levels.

show_lives(lives$subcluster, "Education")
```


```{r}
#| label: tbl-s-lives-field
#| tbl-cap: Distribution of the fields of education.

show_lives(lives$subcluster, "Field")
```


```{r}
#| label: tbl-s-lives-occupation
#| tbl-cap: Distribution of occupational fields.

show_lives(lives$subcluster, "Occupation")
```


Complete summary of the education, fields of the study and occupation data from the sample, classified in sub-clusters with the cluster model and the VVIQ groups.
:::

&nbsp;
&nbsp;
&nbsp;

::: {.callout-note collapse="true"}
# Session information

```{r}
#| label: session-information

sessioninfo::session_info(pkgs = "attached")
```
:::
